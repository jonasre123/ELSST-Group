{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General approach\n",
    "- Make all terms lowercase\n",
    "- Identify German nouns with a list and convert these to upper case\n",
    "\n",
    "## Challenges\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read Excel and convert everything in the 'object' column to  lower case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('ELSST_R3_DE.xlsx')\n",
    "print(len(df.index))\n",
    "\n",
    "count = range(1,len(df.index))\n",
    "\n",
    "for i in count:\n",
    "    old = df['object'][i]\n",
    "    new = old.lower()\n",
    "    df = df.replace(old,new)\n",
    "\n",
    "df.to_excel('forELSSTGroup\\GER_ELSST_lowercase.xlsx', sheet_name='Sheet 1')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Compile a list of nouns and verbs\n",
    "I used the csv-list offered here: https://pypi.org/project/german-nouns/. It was compiled from WiktionaryDE. The list had a number of issues and I have done a lot of trimming to it to improve it based on the results I received. Among the issues were very short nouns, names of cities, etc. The outcome of this is a text file with each noun (including different forms) on an individual line. \n",
    "I ended up compiling a list of verbs too ensure that verbs weren't capizalized, but the results are sketchy. \n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Set the beginning of the definitions and the scope notes to uppercase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "wb = openpyxl.load_workbook(\"forELSSTGroup\\GER_ELSST_lowercase.xlsx\")\n",
    "ws = wb[\"Sheet 1\"]\n",
    "\n",
    "for r in range(1,ws.max_row+1):\n",
    "    label = ws.cell(r,3).value\n",
    "    terms = ws.cell(r,4).value\n",
    "    if label == \"definition_de\" or label == \"scopeNote_de\":\n",
    "        ws.cell(r,4).value = ws.cell(r,4).value.replace(terms[0], terms[0].capitalize(),1)\n",
    "\n",
    "wb.save(\"forELSSTGroup\\GER_ELSST_definitions.xlsx\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Capitalize all words in the list of nouns and NOT in the list of verbs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import re\n",
    "\n",
    "with open('wortliste/neue_nomenliste.txt', 'r', encoding=\"utf8\") as f:\n",
    "    nomen = [line.strip() for line in f]\n",
    "\n",
    "with open('wortliste/neue_verben.txt', 'r', encoding=\"utf8\") as f:\n",
    "    verben = [line.strip() for line in f]    # to do replace ö,ü,ä,\n",
    "\n",
    "wb = openpyxl.load_workbook(\"forELSSTGroup\\GER_ELSST_definitions.xlsx\")\n",
    "ws = wb[\"Sheet 1\"]\n",
    "\n",
    "for wort in nomen:\n",
    "    for r in range(1,ws.max_row+1):            \n",
    "        terms = ws.cell(r,4).value\n",
    "        label = ws.cell(r,3).value\n",
    "        for item in terms.split(' '):             \n",
    "            if not re.search(r\"\\W\",item): # identifies every string that doesn't have a comma, parentheses or other non-word character in it\n",
    "                if item != item.capitalize() and item not in verben:\n",
    "                    if item == wort.lower():\n",
    "                            to_replace = r\"\\b\" + item + r\"\\b\"\n",
    "                            ws.cell(r,4).value = re.sub(to_replace, item.capitalize(),ws.cell(r,4).value)\n",
    " \n",
    "            else:\n",
    "                if re.search(r\"^[(']\",item): # checks if the string begins with parantheses or single quotation marks\n",
    "                    if wort.lower() == item[1:-1] and item[1:-1] not in verben:\n",
    "                        ws.cell(r,4).value = re.sub(re.escape(item[1:-1]),re.escape(wort),ws.cell(r,4).value)\n",
    "                            #print(f\"New value for (': {ws.cell(r,4).value}\")\n",
    "                    elif wort.lower() == item[1:-2]:\n",
    "                        ws.cell(r,4).value = re.sub(re.escape(item[1:-2]),re.escape(wort),ws.cell(r,4).value)\n",
    "             \n",
    "                else:\n",
    "                    if re.search(r\"[\\.,]\",item): # checks if the string has a comma or full stop\n",
    "                        if wort.lower() == item[:-1] and item[:-1] not in verben:\n",
    "                            to_replace = re.search(r\"\\b\"+item[:-1],item)\n",
    "                            if to_replace:\n",
    "                                ws.cell(r,4).value = re.sub(r\"\\b\"+to_replace.group()+r\"\\b\",wort,ws.cell(r,4).value)\n",
    "\n",
    "wb.save('forELSSTGroup\\GER_ELSST_targetfile1.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Capitalize all words which end in typical noun suffixes (heit, keit, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import re\n",
    "\n",
    "wb = openpyxl.load_workbook(\"forELSSTGroup\\GER_ELSST_targetfile1.xlsx\")\n",
    "ws = wb[\"Sheet 1\"]\n",
    "\n",
    "heit = [\"ing\",\"heit\",\"heiten\", \"keit\",\"keiten\", \"ung\", \"ungen\" ,\"nis\", \"nisse\",\"nissen\", \"schaft\", \"schaften\", \"tum\",\"tümer\"]\n",
    "\n",
    "for endung in heit:\n",
    "    endungen = endung + r\"\\b\"\n",
    "    for r in range(1,ws.max_row+1):\n",
    "    #for r in range(1,50):\n",
    "        terms = ws.cell(r,4).value\n",
    "        for item in terms.split(' '):\n",
    "            if not re.search('\\W',item):\n",
    "                if item != item.capitalize():\n",
    "                    #print(item)\n",
    "                    match = re.search(endungen, item)\n",
    "                    if match:\n",
    "                        #print(item)\n",
    "                        ws.cell(r,4).value = re.sub(item, item.capitalize(),ws.cell(r,4).value)\n",
    "                        #print(ws.cell(r,4).value)\n",
    "wb.save('forELSSTGroup\\GER_ELSST_targetfile2.xlsx') \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Capitalize compounds ending in a noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import re\n",
    "\n",
    "#nomen = ['Größe','Grösse','Verein', 'Vereine','Vereinigung','Vereinigungen','Dienstleistung','Dienstleistungen','Gruppe','Gruppen','Aengste', 'Angststoerungen', 'Angststörungen', 'Angstzustaende', 'Angstzustände', 'Anhaenger', 'Anhänger', 'Anrufe', 'Ausbildung', 'Ausbildung', 'Badminton', 'Befähigung', 'Begriff', 'Beschaeftigung', 'Beschäftigung', 'Bestimmung', 'Bildung', 'Bildung', 'Boxen', 'Bundespraesidenten', 'Bundespräsidenten', 'Chancen', 'Darlehen', 'Depression', 'Depressionen', 'Desinformation', 'Diagnose', 'Diagnosen', 'Diagnostik', 'Dienstleistungen', 'Downer', 'Energie', 'Energieeffizienz', 'Energieeinsparung', 'Ergebnisse', 'Ernährung', 'Erwartung', 'Erwartungen', 'Fachgebiete', 'Falschmeldung', 'Falschmeldungen', 'Fans', 'Fernstudium', 'Fernunterricht', 'Flugverkehr', 'Freimaurerei', 'Gebuehren', 'Gebühren', 'Gesundheitswesen', 'Gruppen', 'Haustiere', 'Heroin', 'Herrscher', 'Interessen', 'Judo', 'Kampfkunst', 'Kampfsport', 'Kandidaten', 'Kandidatin', 'Kindern', 'Klassenarbeiten', 'Klausuren', 'Koexistenz', 'Kolonialismus', 'Krankengeschichte', 'Krankenhauspatienten', 'Krankheit', 'Krieg', 'Kriege', 'Kriegfuehrung', 'Kriegführung', 'Kriegsfuehrung', 'Kriegsführung', 'Labortests', 'Lastautos', 'Lastkraftwagen', 'Lastwagen', 'Lehrberuf', 'Lehrtaetigkeit', 'Lehrtätigkeit', 'Linguistik', 'Lkw', 'Luftverkehr', 'Marine', 'Minderheiten', 'Minoritaeten', 'Minoritäten', 'Mitglieder', 'Monarchen', 'Niedergeschlagenheit', 'Optometrie', 'Partei', 'Patienten', 'Person', 'Pharmakologie', 'Pharmazie', 'Praesidenten', 'Prothetik', 'Präsidenten', 'Regenten', 'Regierung', 'Rehabilitation', 'Ringen', 'Rueckschlagspiele', 'Rückschlagspiele', 'Saisonarbeit', 'Schlaegern', 'Schlägern', 'Schularbeiten', 'Schuldienst', 'Seestreitkraefte', 'Seestreitkräfte', 'Sport', 'Sportarten', 'Sprachen', 'Sprachstudium', 'Sprachunterricht', 'Sprachwissenschaft', 'Sprachwissenschaften', 'Squash', 'Staatsoberhaeupter', 'Staatsoberhäupter', 'Stalking', 'Studentenvertretungen', 'Studium', 'Studium', 'Symptome', 'Telefonanrufe', 'Telefonate', 'Telefongespraeche', 'Telefongespräche', 'Tennis', 'Teste', 'Tests', 'Therapie', 'Tiere', 'Touren', 'Vereine', 'Vereinigungen', 'Verhalten', 'Volksgesundheit', 'Waehlen', 'Wahl', 'Wandern', 'Wanderungen', 'Wasserturbinen', 'Wohngeld', 'Wrestling', 'Wählen', 'Zollkontrolle', 'Zusammenleben', 'Ängste']\n",
    "with open('wortliste/neue_nomenliste.txt', 'r', encoding=\"utf8\") as f:\n",
    "    nomen = [line.strip() for line in f]\n",
    "with open('wortliste/verben.txt', 'r', encoding=\"utf8\") as f:\n",
    "    verben = [line.strip() for line in f]   \n",
    "\n",
    "wb = openpyxl.load_workbook(\"forELSSTGroup\\GER_ELSST_targetfile2.xlsx\")\n",
    "ws = wb[\"Sheet 1\"]\n",
    "\n",
    "for wort in nomen:\n",
    "    komposit = r\"\\b[a-z,ä,ü,ö,ß]+\" + re.escape(wort.lower()) + r\"\\b\"\n",
    "    #for r in range(113,121):\n",
    "    for r in range(1,ws.max_row+1):    \n",
    "        terms = ws.cell(r,4).value\n",
    "        for item in terms.split(' '):\n",
    "            if item not in verben:            \n",
    "                if not re.search('\\W',item):                \n",
    "                    if item != item.capitalize():\n",
    "                        #print(item)\n",
    "                        match = re.search(komposit, item)\n",
    "                        if match:\n",
    "                            #print(match.group())\n",
    "                            ws.cell(r,4).value = re.sub(r\"\\b\"+komposit+r\"\\b\", item.capitalize(),ws.cell(r,4).value)\n",
    "                            #print(f\"new value: {ws.cell(r,4).value}\")\n",
    "                \n",
    "                else:\n",
    "                    #erfolgsmessgrösse.\n",
    "                    wordmatch = komposit + r\"[\\.,]\"\n",
    "                    if re.search(wordmatch, item):\n",
    "                        if item[:-1] not in verben:\n",
    "                            ws.cell(r,4).value = re.sub(r\"\\b\"+item[:-1]+r\"\\b\", item[:-1].capitalize(),ws.cell(r,4).value)\n",
    "wb.save('forELSSTGroup\\GER_ELSST_targetfile3.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3aa833677d0236431a89a9ceac21c395b83c03e93adb8e7b1696e717442601c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
